{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droste Test Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Droste!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello Droste!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic XGBoost Example\n",
      "preds: [ 0.28583017  0.92392391  0.28583017 ...,  0.92392391  0.05169873\n",
      "  0.92392391]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import urllib.request\n",
    "\n",
    "print('Basic XGBoost Example')\n",
    "# read in data\n",
    "train_url = \"https://raw.githubusercontent.com/dmlc/xgboost/master/demo/data/agaricus.txt.train\"\n",
    "train_file, _ = urllib.request.urlretrieve(train_url)\n",
    "# with urllib.request.urlopen(train_url) as response:\n",
    "#    train_data = response.read().decode('utf-8')\n",
    "dtrain = xgb.DMatrix(train_file)\n",
    "\n",
    "test_url = \"https://raw.githubusercontent.com/dmlc/xgboost/master/demo/data/agaricus.txt.test\"\n",
    "test_file, _ = urllib.request.urlretrieve(test_url)\n",
    "# with urllib.request.urlopen(test_url) as response:\n",
    "#    test_data = response.read().decode('utf-8')\n",
    "dtest = xgb.DMatrix(test_file)\n",
    "\n",
    "# specify parameters via map\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "# make prediction\n",
    "preds = bst.predict(dtest)\n",
    "print(\"preds:\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Examples\n",
      "Zeros and Ones from the Digits dataset: binary classification\n",
      "[[87  0]\n",
      " [ 1 92]]\n",
      "[[91  0]\n",
      " [ 3 86]]\n",
      "Iris: multiclass classification\n",
      "[[19  0  0]\n",
      " [ 0 31  3]\n",
      " [ 0  1 21]]\n",
      "[[31  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  3 25]]\n",
      "Boston Housing: regression\n",
      "9.8628146628\n",
      "15.989963927\n",
      "Parameter optimization\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "0.598487920717\n",
      "{'n_estimators': 100, 'max_depth': 4}\n",
      "Pickling sklearn API models\n",
      "True\n",
      "[0]\tvalidation_0-auc:0.999497\n",
      "Will train until validation_0-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.999497\n",
      "[2]\tvalidation_0-auc:0.999497\n",
      "[3]\tvalidation_0-auc:0.999749\n",
      "[4]\tvalidation_0-auc:0.999749\n",
      "[5]\tvalidation_0-auc:0.999749\n",
      "[6]\tvalidation_0-auc:0.999749\n",
      "[7]\tvalidation_0-auc:0.999749\n",
      "[8]\tvalidation_0-auc:0.999749\n",
      "[9]\tvalidation_0-auc:0.999749\n",
      "[10]\tvalidation_0-auc:1\n",
      "[11]\tvalidation_0-auc:1\n",
      "[12]\tvalidation_0-auc:1\n",
      "[13]\tvalidation_0-auc:1\n",
      "[14]\tvalidation_0-auc:1\n",
      "[15]\tvalidation_0-auc:1\n",
      "[16]\tvalidation_0-auc:1\n",
      "[17]\tvalidation_0-auc:1\n",
      "[18]\tvalidation_0-auc:1\n",
      "[19]\tvalidation_0-auc:1\n",
      "[20]\tvalidation_0-auc:1\n",
      "Stopping. Best iteration:\n",
      "[10]\tvalidation_0-auc:1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import load_iris, load_digits, load_boston\n",
    "\n",
    "# https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_examples.py\n",
    "print(\"Scikit-learn Examples\")\n",
    "\n",
    "rng = np.random.RandomState(31337)\n",
    "\n",
    "print(\"Zeros and Ones from the Digits dataset: binary classification\")\n",
    "digits = load_digits(2)\n",
    "y = digits['target']\n",
    "X = digits['data']\n",
    "kf = KFold(y.shape[0], n_folds=2, shuffle=True, random_state=rng)\n",
    "for train_index, test_index in kf:\n",
    "    xgb_model = xgb.XGBClassifier().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(confusion_matrix(actuals, predictions))\n",
    "\n",
    "print(\"Iris: multiclass classification\")\n",
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data']\n",
    "kf = KFold(y.shape[0], n_folds=2, shuffle=True, random_state=rng)\n",
    "for train_index, test_index in kf:\n",
    "    xgb_model = xgb.XGBClassifier().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(confusion_matrix(actuals, predictions))\n",
    "\n",
    "print(\"Boston Housing: regression\")\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "kf = KFold(y.shape[0], n_folds=2, shuffle=True, random_state=rng)\n",
    "for train_index, test_index in kf:\n",
    "    xgb_model = xgb.XGBRegressor().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(mean_squared_error(actuals, predictions))\n",
    "\n",
    "print(\"Parameter optimization\")\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "clf = GridSearchCV(xgb_model,\n",
    "                   {'max_depth': [2,4,6],\n",
    "                    'n_estimators': [50,100,200]}, verbose=1)\n",
    "clf.fit(X,y)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# The sklearn API models are picklable\n",
    "print(\"Pickling sklearn API models\")\n",
    "# must open in binary format to pickle\n",
    "pickle.dump(clf, open(\"best_boston.pkl\", \"wb\"))\n",
    "clf2 = pickle.load(open(\"best_boston.pkl\", \"rb\"))\n",
    "print(np.allclose(clf.predict(X), clf2.predict(X)))\n",
    "\n",
    "# Early-stopping\n",
    "\n",
    "X = digits['data']\n",
    "y = digits['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "        eval_set=[(X_test, y_test)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
